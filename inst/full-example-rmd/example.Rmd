---
title: "A Full Example with the stcos Package"
author: Andrew Raim
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

# Preparing Your Data
First we will prepare a small dataset for demonstration purposes. The `stcos` package makes use of the `sf` ("Simple Features") package for shapefile manipulation; the inputs to `stcos` are prepared as `sf` objects.
* An `sf` object to serve as the fine-level support.
* An `sf` object for for each (year, lookback) source support. These should have direct estimates and associated variance estimates baked in, and will be used to train the model. 

Let us load some necessary packages.

```{r}
library(sf)
library(dplyr)
```

For our fine-level domain, we will use counties in PA. We will need to get a shapefile with the county boundaries.
1. Navigate to <https://data-pennshare.opendata.arcgis.com/datasets?q=Boundary>, to access boundary shapefiles from the Pennslyvania Dept of Transportation website.
2. Select "County Boundary"
3. Select "Download" and then "Shapefile".
3. Unzip the downloaded file.

The `sf` package currently produces a lot of warnings when using the original projection of this shapefile. Therefore, we transform to a different projection (EPSG 3857).

```{r}
dom.fine <- st_read("C:/Users/raim0001/Downloads/County_Boundary.shp") %>%
	st_transform(3857)
head(dom.fine)
plot(dom.fine[,1], col = NA, main = "PA Counties")
```

Now generate some numbers to use as direct estimates and associated variance estimates. These are currently not realistic in any way, but will be enough to demonstrate how to use the software.

``` {r}
year.levels <- 2010:2015

mean.counties <- rnorm(nrow(dom.fine), mean = 100, sd = 10)
var.counties <- rnorm(nrow(dom.fine), mean = 10, sd = 1)

source.supps.1yr <- list()
for (j in 1:length(year.levels)) {
	year <- year.levels[j]
	supp <- dom.fine
	supp$DirectEst <- rnorm(nrow(dom.fine), 100,  10)
	supp$DirectVar <- 1
	source.supps.1yr[[as.character(year)]] <- supp
}

source.supps.3yr <- list()
for (j in 1:length(year.levels)) {
	if (j < 3) next
	year <- year.levels[j]
	supp <- dom.fine
	supp$DirectEst <- 
		source.supps.1yr[[as.character(year-2)]]$DirectEst / 3 +
		source.supps.1yr[[as.character(year-1)]]$DirectEst / 3 +
		source.supps.1yr[[as.character(year)]]$DirectEst / 3
	supp$DirectVar <- 
		source.supps.1yr[[as.character(year-2)]]$DirectVar / 3 +
		source.supps.1yr[[as.character(year-1)]]$DirectVar / 3 +
		source.supps.1yr[[as.character(year)]]$DirectVar / 3
	source.supps.3yr[[as.character(year)]] <- supp
}

source.supps.5yr <- list()
for (j in 1:length(year.levels)) {
	if (j < 5) next
	year <- year.levels[j]
	supp <- dom.fine
	supp$DirectEst <- 
		source.supps.1yr[[as.character(year-4)]]$DirectEst / 5 +
		source.supps.1yr[[as.character(year-3)]]$DirectEst / 5 +
		source.supps.1yr[[as.character(year-2)]]$DirectEst / 5 +
		source.supps.1yr[[as.character(year-1)]]$DirectEst / 5 +
		source.supps.1yr[[as.character(year)]]$DirectEst / 5
	supp$DirectVar <- 
		source.supps.1yr[[as.character(year-4)]]$DirectVar / 5 +
		source.supps.1yr[[as.character(year-3)]]$DirectVar / 5 +
		source.supps.1yr[[as.character(year-2)]]$DirectVar / 5 +
		source.supps.1yr[[as.character(year-1)]]$DirectVar / 5 +
		source.supps.1yr[[as.character(year)]]$DirectVar / 5
	source.supps.5yr[[as.character(year)]] <- supp
}
```

# Preparing the Model
Select knots for use with the areal bisquare basis function. Spatial knots are selected using a space-filling design via the `fields` package. Once the knots are selected, we create a `SpaceTimeBisquareBasis` object.

```{r}
library(fields)
library(stcos)

# Spatial knots are selected via space-filling design
u <- st_sample(dom.fine, size = 2000)
M <- matrix(unlist(u), length(u), 2, byrow = TRUE)
out <- cover.design(M, 100)
knots.sp <- out$design

# Temporal knots are selected to be evenly spaced
knots.t <- seq(2010, 2015, by = 0.5)

# Combined spatio-temporal knots
knots <- merge(knots.sp, knots.t)
names(knots) <- c("x", "y", "t")

# Create a Basis object
basis <- SpaceTimeBisquareBasis$new(knots[,1], knots[,2], knots[,3], w.s = 1, w.t = 1)
```

Now create a `STCOSPrep` object, which will help us to build all of the quantities needed to fit the STCOS model.
```{r}
sp <- STCOSPrep$new(fine_domain = dom.fine, fine_domain_geo_name = "FIPS_ID",
    basis = basis, basis_mc_reps = 25)

for (j in 1:length(year.levels)) {
	year <- year.levels[j]
	sp$add_obs(source.supps.1yr[[as.character(year)]], period = year,
		estimate_name = "DirectEst", variance_name = "DirectVar",
		geo_name = "FIPS_ID")
}

for (j in 1:length(year.levels)) {
	if (j < 3) next
	year <- year.levels[j]
	sp$add_obs(source.supps.3yr[[as.character(year)]], period = seq(year-2, year),
		estimate_name = "DirectEst", variance_name = "DirectVar",
		geo_name = "FIPS_ID")
}

for (j in 1:length(year.levels)) {
	if (j < 5) next
	year <- year.levels[j]
	sp$add_obs(source.supps.5yr[[as.character(year)]], period = seq(year-4, year),
		estimate_name = "DirectEst", variance_name = "DirectVar",
		geo_name = "FIPS_ID")
}
```

Extract the quantities needed to fit the STCOS model.
```{r}
Z <- sp$get_Z()
V <- sp$get_V()
H <- sp$get_H()
S <- sp$get_S()
```

Do some dimention reduction on the `S` matrix. From past experience, the draws from the Gibbs sampler have come out very poorly if we fit the model with the full `S` matrix. Note that we need to tell our `STCOSPrep` object which dimension reduction we used, so that an equivalent operation can be done when constructing the `K` matrix.

```{r}
eig <- eigen(t(S) %*% S)
rho <- eig$values

idx.S <- which(cumsum(rho) / sum(rho) < 0.90)
Tx.S <- t(eig$vectors[idx.S,])
f <- function(S) { S %*% Tx.S }
sp$set_basis_reduction(f)

S.reduced <- sp$get_reduced_S()
```

Now construct the inverse of the `K` matrix. There are several options we have considered.
```{r}
method <- 1
if (method == 1) {
	# Random Walk
	K.inv <- sp$get_Kinv(2005:2015)
} else if (method == 2) {
	# Spatial-only
	K.inv <- sp$get_Kinv(2005:2015, autoreg = FALSE)
} else if (method == 3) {
	# Independence
	K.inv <- diag(x = 1, nrow = ncol(S.reduced))
} else {
	stop("method should be 1, 2, or 3")
}
```

# Fitting the Model
First we standardize the inputs so that the estimates `Z` have mean 0 and sd 1. Past experience has shown that draws from the Gibbs sampler can come out poorly if this is not done.
```{r}
D <- Diagonal(n = length(Z), x = 1/sd(Z))
Z.scaled <- (Z - mean(Z)) / sd(Z)
V.scaled <- V / var(Z)
```

Compute an MLE as initial value for Gibbs sampler.
```{r}
mle.out <- mle.stcos(Z.scaled, S.reduced, V.scaled, H, init = list(sig2xi = 1))
init <- list(
    sig2xi = mle.out$sig2xi.hat,
    mu_B = mle.out$mu.hat,
    eta = mle.out$eta.hat
)
```

Now run the Gibbs sampler.
```{r}
gibbs.out <- gibbs.stcos.raw(Z.scaled, S.reduced, V.scaled, K.inv, H, R = 5000,
    report.period = 1000, burn = 500, thin = 10, init = init)
print(gibbs.out)
```

Once the sampler is finished, we can extract the draws and examine some diagnostics (such as trace plots).
```{r}
library(coda)

plot(mu_B.mcmc <- mcmc(gibbs.out$mu_B.hist)[,1:3])
plot(eta.mcmc <- mcmc(gibbs.out$eta.hist)[,1:3])
plot(xi.mcmc <- mcmc(gibbs.out$xi.hist)[,1:3])
sig2mu.mcmc <- mcmc(gibbs.out$sig2mu.hist)
sig2xi.mcmc <- mcmc(gibbs.out$sig2xi.hist)
sig2K.mcmc <- mcmc(gibbs.out$sig2K.hist)
plot(mcmc(cbind(sig2mu.mcmc, sig2xi.mcmc, sig2K.mcmc)))
```

# Producing Results on Target Geographies
Let's set up a fake target support by making a coarse grid over the state of PA. This code was adapted from a post at <https://gis.stackexchange.com/questions/225157/generate-rectangular-fishnet-or-vector-grid-cells-shapefile-in-r/243585>. We remove squares of the grid that extend outside of the state.

```{r}
gridn <- 6
dom.target <- st_make_grid(dom.fine, n = c(gridn, gridn), what = 'polygons') %>%
	st_sf('geometry' = ., data.frame('GEO_ID' = 1:length(.))) %>%
	st_transform(st_crs(dom.fine)) %>%
	filter(!(GEO_ID %in% c(6,12,18,24,30,31:36)))

plot(dom.fine[,"COUNTY_NAM"])
plot(dom.target[,1], col = NA, lwd = 2, add = TRUE)
```

Set up `H` and `S` matrices for the grid geography, then produce estimates on this geography using the draw from our Gibbs sampler. We place the estimates back into the `sf` object, so that they may be easily plotted.
```{r}
# Compute H and S matrices
target.out <- sp$domain2model(dom.target, period = 2015, geo_name = "GEO_ID")

# Posterior distribution for E(Y)
E.hat.scaled <- fitted(gibbs.out, target.out$H, target.out$S.reduced)
E.hat <- sd(Z) * E.hat.scaled + mean(Z)                      # Uncenter and unscale
dom.target$E.mean <- colMeans(E.hat)                         # Point estimates
dom.target$E.sd <- apply(E.hat, 2, sd)                       # SDs
dom.target$E.lo <- apply(E.hat, 2, quantile, prob = 0.025)   # Credible interval lo
dom.target$E.hi <- apply(E.hat, 2, quantile, prob = 0.975)   # Credible interval hi

# Posterior predictive distribution of Y
Y.pred.scaled <- predict(gibbs.out, target.out$H, target.out$S.reduced)
Y.pred <- sd(Z) * Y.pred.scaled + mean(Z)                    # Uncenter and unscale
dom.target$PP.mean <- colMeans(Y.pred)                       # Point estimates
dom.target$PP.sd <- apply(Y.pred, 2, sd)                     # SDs
dom.target$PP.lo <- apply(Y.pred, 2, quantile, prob = 0.025) # Prediction interval lo
dom.target$PP.hi <- apply(Y.pred, 2, quantile, prob = 0.975) # Prediction interval hi
```

Now the estimates are embedded in the `sf` object.
```{r}
head(dom.target)
```

The `plot` command can be used to generate some quick plots. We'll demonstrate `ggplot2` later, which can be used to make more customizable plots.
```{r}
plot(dom.target[,"E.mean"])
plot(dom.target[,"PP.mean"])
plot(dom.target[,"E.sd"])
plot(dom.target[,"PP.sd"])
```

Now let's produce estimates using a particular source support as a target support.
```{r}
d2 <- source.supps.1yr[["2015"]]
target2.out <- sp$domain2model(d2, period = 2015, geo_name = "FIPS_ID")

E.hat.scaled <- fitted(gibbs.out, target2.out$H, target2.out$S.reduced)
E.hat <- sd(Z) * E.hat.scaled + mean(Z)            # Uncenter and unscale
d2$E.mean <- colMeans(E.hat)                       # Point estimates
d2$E.sd <- apply(E.hat, 2, sd)                     # SDs
d2$E.lo <- apply(E.hat, 2, quantile, prob = 0.025) # Credible interval lo
d2$E.hi <- apply(E.hat, 2, quantile, prob = 0.975) # Credible interval hi

plot(d2[,c("DirectEst", "E.mean")])

plot(d2$DirectEst, d2$E.mean)
```

# Plotting with ggplot2
The `ggplot2` package can plot `sf` objects, but this functionality is not yet available on the CRAN version of `ggplot2`. To obtain the latest development version of `ggplot2`, navigate to <https://github.com/tidyverse/ggplot2> and follow the instructions under "Installation". Then we may produce plots like the following.

``` {r}
library(ggplot2)
library(gridExtra)

lim.est <- range(d2$DirectEst, d2$E.mean)

g <- ggplot(d2) +
	geom_sf(colour = "black", size = 0.05, aes(fill = DirectEst)) +
	ggtitle("Median Household Income for Coarse Grid") +
	scale_fill_distiller("DirectEst", palette = "RdYlBu", limits = lim.est) +
	theme_bw()
plot(g)

h <- ggplot(d2) +
	geom_sf(colour = "black", size = 0.05, aes(fill = E.mean)) +
	ggtitle("Median Household Income for Coarse Grid") +
	scale_fill_distiller("E.mean", palette = "RdYlBu", limits = lim.est) +
	theme_bw()
plot(h)

grid.arrange(g,h)
```
